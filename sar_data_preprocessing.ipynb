{
  "cells": [
    
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t78flOZtroCY",
        "outputId": "bcf97215-6558-4248-b0fc-d5461b5c6687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing a 3200 * 3200 chunk"
      ],
      "metadata": {
        "id": "YrthUgVxCHh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage as ski\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from skimage.morphology import max_tree, label\n",
        "import networkx as nx\n",
        "\n",
        "def area_filtering(image, area_threshold):\n",
        "    \"\"\"Filter image based on area criteria.\"\"\"\n",
        "    labeled_image, num_features = label(image, connectivity=2, return_num=True)\n",
        "    component_areas = np.bincount(labeled_image.ravel())\n",
        "\n",
        "    for component_label in range(1, num_features + 1):\n",
        "        if component_areas[component_label] <= area_threshold:\n",
        "            image[labeled_image == component_label] = 0\n",
        "\n",
        "    return image\n",
        "\n",
        "def automatic_contrast_stretching(image, lower_percentile=5, upper_percentile=95):\n",
        "    # Compute the lower and upper bounds using percentiles\n",
        "    lower_bound = np.percentile(image, lower_percentile)\n",
        "    upper_bound = np.percentile(image, upper_percentile)\n",
        "\n",
        "    # Apply the contrast stretching formula\n",
        "    stretched_image = np.clip((image - lower_bound) * 255 / (upper_bound - lower_bound), 0, 255)\n",
        "    stretched_image = stretched_image.astype(np.uint16)\n",
        "\n",
        "    return stretched_image # Add return statement to send processed image back\n",
        "\n",
        "def process(chunk,chunk_name):\n",
        "\n",
        "  chunk_contrast_stretching = automatic_contrast_stretching(chunk)\n",
        "  # cv2.imwrite(os.path.join('contrast_stretched.jpg'), chunk_contrast_stretching)\n",
        "\n",
        "  # blur before thresholding\n",
        "  # high blurring so that larger landmasses are more connected\n",
        "  blurred_image = chunk_contrast_stretching\n",
        "  cv2.boxFilter(blurred_image, -1, (10,10), normalize=True, borderType=cv2.BORDER_CONSTANT)\n",
        "\n",
        "  # perform automatic thresholding to get threshold for height\n",
        "  t = ski.filters.threshold_otsu(blurred_image)\n",
        "  # cv2.imwrite(os.path.join('blurred.jpg'), blurred_image)\n",
        "  # print(t)\n",
        "\n",
        "  # Step 2: Filter using Height Criteria\n",
        "  height_threshold = t/2\n",
        "  outheight = blurred_image >= height_threshold\n",
        "  outheight = np.where( outheight, 255, 0).astype(np.uint8) # binary 0 or 255\n",
        "  outheight2 = np.copy(outheight)\n",
        "  # cv2.imwrite(os.path.join('outheight.jpg'), outheight2 )\n",
        "\n",
        "  # Step 3: Filter using Area Criteria\n",
        "  area_threshold = 3200 # Example threshold (approximate ship area of 400m)\n",
        "  outarea = area_filtering(outheight, area_threshold)\n",
        "  outarea = np.where( outarea, 255, 0).astype(np.uint8)\n",
        "  # cv2.imwrite(os.path.join('outarea.jpg'), outarea)\n",
        "\n",
        "  # Create a mask where outarea has value 0 (so everything except large landmass)\n",
        "  mask = (outarea == 0)\n",
        "  # Apply the mask to retain original values from image where the mask is True\n",
        "  resultant_image = np.where(mask, chunk, 0)\n",
        "  # cv2.imwrite(os.path.join('resultant.jpg'), resultant_image)\n",
        "  threshold = resultant_image.max() # brightest pixel value in smaller components (ship)\n",
        "  print(threshold)\n",
        "  print(chunk.max())\n",
        "\n",
        "  # Cap values at threshold, This ensures that any value greater than threshold is set to threshold.\n",
        "  capped_image = np.minimum(chunk, threshold)\n",
        "  # This normalizes the image so that the minimum value becomes 0 and the maximum value becomes 255.\n",
        "  normalized_image = cv2.normalize(capped_image, None, 0, 255, cv2.NORM_MINMAX)\n",
        "  # change datatype from uint16 to uint8\n",
        "  final_image = normalized_image.astype(np.uint8)\n",
        "  # cv2.imwrite(os.path.join('final.jpg'), final_image)\n",
        "\n",
        "  return final_image\n",
        "\n",
        "  # # Step 4: Subtract the filtered image\n",
        "  # result_image = outheight2 - outarea\n",
        "  # # cv2.imwrite(os.path.join('connected_components.jpg'), outheight2 - outarea)\n",
        "\n",
        "  # # Create a mask where resultant image has 255\n",
        "  # mask = (result_image == 255)\n",
        "\n",
        "  # # Apply the mask to retain original values from image where the mask is True\n",
        "  # resultant_image = np.where(mask, blurred_image, 0)\n",
        "  # threshold = resultant_image.max()\n",
        "  # # print(threshold)\n",
        "\n",
        "  # # cv2.imwrite(os.path.join('resultant.jpg'), resultant_image)\n",
        "  # threshold = resultant_image.max()/blurred_image.max()\n",
        "  # print( blurred_image.max())\n",
        "  # print(\"Threshold final for \"+chunk_name+\": \",threshold)\n",
        "\n",
        "  # print(\"Initial max and min of chunk: \",chunk.max(),chunk.min())\n",
        "  # chunk1 = (chunk - chunk.min()) / (chunk.max() - chunk.min())\n",
        "\n",
        "  # chunk1 = (chunk1 > threshold).astype(np.uint16)\n",
        "\n",
        "  # chunk1=np.ma.masked_array(chunk, mask=chunk1)\n",
        "  # print(\"Final max and min of chunk: \",chunk1.max(),chunk1.min())\n",
        "  # return chunk\n",
        ""
      ],
      "metadata": {
        "id": "tlvDumjZCG4A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further divide from 3200 * 3200 to 800 * 800 sz images"
      ],
      "metadata": {
        "id": "YnPrpSk4wIM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_further(chunk, chunk_name, OUTPUT_DIR, window_size_final):\n",
        "  row=0\n",
        "  window_size = window_size_final\n",
        "  dataraster = chunk\n",
        "  xSize = 3200\n",
        "  ySize = 3200 # (size of the larger chunk)\n",
        "  while row < ySize:\n",
        "          col=0\n",
        "          while col < xSize:\n",
        "            if row + window_size <= ySize and col + window_size <= xSize:\n",
        "                  data_value = dataraster[row:row + window_size, col:col + window_size]\n",
        "                  cv2.imwrite(os.path.join(OUTPUT_DIR + chunk_name + '_' + str(row) + '_' + str(col) + '.jpg'), data_value)\n",
        "            else:\n",
        "                  pass\n",
        "            col=col+window_size\n",
        "          row=row+window_size"
      ],
      "metadata": {
        "id": "pv6Grln-rF6F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starts processing of dataraster"
      ],
      "metadata": {
        "id": "sHMbjNdHwhvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "from scipy import stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "\n",
        "def processRaster(dataraster,OUTPUT_DIR_PROCESSED,OUTPUT_DIR_DIRECT,window_size_final,xSize,ySize):\n",
        "\n",
        "  '''\n",
        "  divides raster into 3200*3200 chunks\n",
        "  processes each chunk\n",
        "  further divides them into the desired window size\n",
        "  '''\n",
        "\n",
        "\n",
        "  global_max=int(dataraster.max())\n",
        "  global_min=int(dataraster.min())\n",
        "  print(\"Max and min values of the dataraster: \",global_max,global_min)\n",
        "  print(\"Shape of dataraster: \", dataraster.shape)\n",
        "\n",
        "  window_size = 3200\n",
        "  row=0\n",
        "  while row < ySize:\n",
        "          print(\"Row=\"+str(row))\n",
        "          col=0\n",
        "          while col < xSize:\n",
        "            if row + window_size <= ySize and col + window_size <= xSize:\n",
        "                  subRaster = dataraster[row:row + window_size, col:col + window_size]\n",
        "\n",
        "                  data_value = numpy.zeros((3, window_size, window_size)).astype(\"uint16\")\n",
        "                  data_value[0, :, :] = subRaster\n",
        "                  data_value[1, :, :] = subRaster\n",
        "                  data_value[2, :, :] = subRaster\n",
        "\n",
        "                  data_value = np.transpose(data_value, (1, 2, 0))\n",
        "\n",
        "                  chunk_name = 'chunk' + str(row) + '_' + str(col)\n",
        "                  processed_chunk = process(data_value,chunk_name)\n",
        "                  divide_further(processed_chunk, chunk_name, OUTPUT_DIR_PROCESSED, window_size_final)\n",
        "                  divide_further(data_value, chunk_name, OUTPUT_DIR_DIRECT, window_size_final) # directly divide without further processing\n",
        "\n",
        "            else:\n",
        "                  pass\n",
        "            col=col+window_size\n",
        "          row=row+window_size\n",
        "  print(\"Done\")\n"
      ],
      "metadata": {
        "id": "a4VMLCUjDVGg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the input Tiff File"
      ],
      "metadata": {
        "id": "BRGbpYNGpG14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal, ogr, osr\n",
        "import os\n",
        "gdal.UseExceptions()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy\n",
        "import cv2\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "def readRaster(INPUT_FILE,OUTPUT_DIR_PROCESSED,OUTPUT_DIR_DIRECT,window_size_final):\n",
        "  '''\n",
        "  read the tiff file and puts it into a numpy array\n",
        "  '''\n",
        "  print(INPUT_FILE)\n",
        "  raster = gdal.Open(INPUT_FILE);\n",
        "  # Get raster georeference info\n",
        "  transform = raster.GetGeoTransform()\n",
        "  xOrigin = transform[0]\n",
        "  yOrigin = transform[3]\n",
        "  pixelWidth = transform[1]\n",
        "  pixelHeight = transform[5]\n",
        "  xSize = raster.RasterXSize\n",
        "  ySize = raster.RasterYSize\n",
        "  print(transform)\n",
        "  # Read raster data as a NumPy array\n",
        "  print(xOrigin,yOrigin,xSize,ySize,pixelWidth,pixelHeight)\n",
        "  dataraster = raster.ReadAsArray(0, 0, xSize, ySize).astype(numpy.uint16)\n",
        "  processRaster(dataraster,OUTPUT_DIR_PROCESSED,OUTPUT_DIR_DIRECT,window_size_final,xSize,ySize)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "69rDX-Nmo92J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input file, Output Dir defined"
      ],
      "metadata": {
        "id": "lN7tULfXw4fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    window_size_final=800\n",
        "    INPUT_FILE='/content/drive/My Drive/S1A_IW_GRDH_1SDV_20240323T152959_20240323T153028_053111_066EE3_3DFF.SAFE/measurement/s1a-iw-grd-vh-20240323t152959-20240323t153028-053111-066ee3-002.tiff'\n",
        "    OUTPUT_DIR_PROCESSED='/content/drive/My Drive/processed_divided_image_chunks/'\n",
        "    OUTPUT_DIR_DIRECT = '/content/drive/My Drive/divided_image_chunks/'\n",
        "\n",
        "    if not os.path.exists(OUTPUT_DIR_PROCESSED):\n",
        "        os.makedirs(OUTPUT_DIR_PROCESSED)\n",
        "\n",
        "    if not os.path.exists(OUTPUT_DIR_DIRECT):\n",
        "        os.makedirs(OUTPUT_DIR_DIRECT)\n",
        "\n",
        "    readRaster(INPUT_FILE,OUTPUT_DIR_PROCESSED,OUTPUT_DIR_DIRECT,window_size_final)"
      ],
      "metadata": {
        "id": "--1-bbgPBsR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORrOjrRs5IA+6kHKSkk/X1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
