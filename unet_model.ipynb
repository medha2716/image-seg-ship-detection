{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJCkxWviopsh/NEr7jFy/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
   
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "IeC3JBOhBQGG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7P9acuu_TbE",
        "outputId": "bcde2278-837d-4a4a-8f5b-6e70a888e57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load JSON data and Images, Extract JSON data"
      ],
      "metadata": {
        "id": "vUq9WMXgBSbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "path_folder_annotations = '/content/drive/My Drive/annotations'\n",
        "path_folder_images = '/content/drive/My Drive/JPEGImages'\n",
        "\n",
        "# Load the JSON files with annotations\n",
        "with open(path_folder_annotations+'/train2017.json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(path_folder_annotations+'/test2017.json', 'r') as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# Extract information from JSON\n",
        "train_images_info = {img['id']: img for img in train_data['images']} # train_images_info[id] gives the 'images' info in the json for that id\n",
        "train_annotations = train_data['annotations']\n",
        "\n",
        "test_images_info = {img['id']: img for img in test_data['images']}\n",
        "test_annotations = test_data['annotations']"
      ],
      "metadata": {
        "id": "FiF-ic6E_irs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Mask Images and add to directory (Run this cell only if train masks and test masks not in drive)"
      ],
      "metadata": {
        "id": "8zkWZ60lBVH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "\n",
        "# Paths in your Google Drive\n",
        "drive_base_path = '/content/drive/My Drive'\n",
        "train_masks_dir = os.path.join(drive_base_path, 'train_masks')\n",
        "test_masks_dir = os.path.join(drive_base_path, 'test_masks')\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(train_masks_dir, exist_ok=True)\n",
        "os.makedirs(test_masks_dir, exist_ok=True)\n",
        "\n",
        "# Function to create mask from annotations\n",
        "def create_mask(image_info, annotations):\n",
        "    image_size=(800, 800)\n",
        "    mask = Image.new('L', image_size, 0)\n",
        "    draw = ImageDraw.Draw(mask)\n",
        "    for annotation in annotations:\n",
        "        if annotation['image_id'] == image_info['id']:\n",
        "            for polygon in annotation['segmentation']:\n",
        "                polygon = [(polygon[i], polygon[i + 1]) for i in range(0, len(polygon), 2)]\n",
        "                draw.polygon(polygon, outline=1, fill=1)\n",
        "    return np.array(mask)\n",
        "\n",
        "def save_grayscale_image(matrix, filename):\n",
        "    # Ensure the values are in the range 0-255\n",
        "    matrix = (matrix * 255).astype(np.uint8)\n",
        "    image = Image.fromarray(matrix)\n",
        "    image.save(filename, 'JPEG')\n",
        "\n",
        "# Function to process images and masks\n",
        "def process_image_and_mask(image_info, annotations, images_path, masks_path):\n",
        "    image_path = os.path.join(images_path, image_info['file_name'])\n",
        "    mask = create_mask(image_info, annotations)\n",
        "    mask_image_path = os.path.join(masks_path, f\"{image_info['file_name']}\")\n",
        "    save_grayscale_image(mask, mask_image_path)\n",
        "\n",
        "    return image_path, mask_image_path\n",
        "\n",
        "# Generate paths for all images and masks in train and test sets\n",
        "train_img_mask_paths = [process_image_and_mask(img_info, train_annotations, path_folder_images, train_masks_dir)\n",
        "                        for img_info in train_images_info.values()]\n",
        "test_img_mask_paths = [process_image_and_mask(img_info, test_annotations, path_folder_images, test_masks_dir)\n",
        "                       for img_info in test_images_info.values()]"
      ],
      "metadata": {
        "id": "xfa2DcaI_m8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Test Mask and Train Mask to Google Drive (saved now)"
      ],
      "metadata": {
        "id": "YiLRHnNpBa2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "\n",
        "# Paths in your Google Drive\n",
        "drive_base_path = '/content/drive/My Drive'\n",
        "train_masks_dir = os.path.join(drive_base_path, 'train_masks')\n",
        "test_masks_dir = os.path.join(drive_base_path, 'test_masks')\n",
        "\n",
        "# Function to process images and masks\n",
        "def process_image_and_mask(image_info, annotations, images_path, masks_path):\n",
        "    image_path = os.path.join(images_path, image_info['file_name'])\n",
        "    mask_image_path = os.path.join(masks_path, f\"{image_info['file_name']}\")\n",
        "    return image_path, mask_image_path\n",
        "\n",
        "# Generate paths for all images and masks in train and test sets\n",
        "train_img_mask_paths = [process_image_and_mask(img_info, train_annotations, path_folder_images, train_masks_dir)\n",
        "                        for img_info in train_images_info.values()]\n",
        "test_img_mask_paths = [process_image_and_mask(img_info, test_annotations, path_folder_images, test_masks_dir)\n",
        "                       for img_info in test_images_info.values()]\n"
      ],
      "metadata": {
        "id": "0XJfQM8HAqB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Tensorflow Datasets"
      ],
      "metadata": {
        "id": "ENqXeD5WBfTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import ImageOps, Image\n",
        "from keras.utils import load_img\n",
        "\n",
        "# Function to load and preprocess images and masks\n",
        "def load_img_masks(input_img_path, target_img_path, img_size=(800, 800)):\n",
        "    input_img = tf.io.read_file(input_img_path)\n",
        "    input_img = tf.image.decode_jpeg(input_img, channels=3)\n",
        "    input_img = tf.image.convert_image_dtype(input_img, tf.uint8)\n",
        "\n",
        "    target_img = tf.io.read_file(target_img_path)\n",
        "    target_img = tf.image.decode_jpeg(target_img, channels=1)\n",
        "    target_img = tf.image.convert_image_dtype(target_img, tf.uint8)\n",
        "\n",
        "    # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
        "    target_img -= 1\n",
        "    return input_img, target_img\n",
        "\n",
        "# TO TEST load_img_masks:\n",
        "# -----------------\n",
        "\n",
        "# def display_img_and_mask(input_img, target_img): # made this function to test\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "\n",
        "#     plt.subplot(1, 2, 1)\n",
        "#     plt.title(\"Input Image\")\n",
        "#     plt.imshow(input_img)\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.subplot(1, 2, 2)\n",
        "#     plt.title(\"Target Mask\")\n",
        "#     plt.imshow(target_img)\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.show()\n",
        "\n",
        "# # Load and preprocess one pair of image and mask\n",
        "# input_img_path = train_img_paths[1]  # Replace with actual image path\n",
        "# target_img_path = train_mask_paths[1]  # Replace with actual mask path\n",
        "\n",
        "# input_img, target_img = load_img_masks(input_img_path, target_img_path)\n",
        "\n",
        "# # Convert tensors to numpy arrays for display\n",
        "# input_img_np = input_img.numpy()\n",
        "# target_img_np = target_img.numpy()\n",
        "\n",
        "# # Display the input image and target mask\n",
        "# display_img_and_mask(input_img_np, target_img_np)\n",
        "\n",
        "# # Actual Dispaly\n",
        "# img = Image.open(input_img_path)\n",
        "# display(img)\n",
        "# img = ImageOps.autocontrast(load_img(target_img_path))\n",
        "# display(img)\n",
        "\n",
        "# -----------------\n",
        "\n",
        "# Function to create a TensorFlow dataset\n",
        "def create_dataset(img_target_paths, batch_size=32, img_size=(800, 800)):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(img_target_paths)\n",
        "    dataset = dataset.map(lambda x: load_img_masks(x[0], x[1]), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = create_dataset(train_img_mask_paths)\n",
        "print(\"Train dataset created\")\n",
        "test_dataset = create_dataset(test_img_mask_paths)\n",
        "print(\"Test dataset created\")\n",
        "\n",
        "print(train_dataset)\n",
        "\n",
        "\n",
        "def preprocess(image, label):\n",
        "    # Resize the image and label\n",
        "    image = tf.image.resize(image, (800,800))\n",
        "    label = tf.image.resize(label, (800,800))\n",
        "\n",
        "    # Ensure the shapes are correct\n",
        "    image.set_shape([800,800, 3])\n",
        "    label.set_shape([800,800, 1])\n",
        "\n",
        "    # Convert the data types\n",
        "    image = tf.cast(image, tf.uint8)\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "processed_train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "processed_test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "print(processed_train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYJSlInZAv1s",
        "outputId": "5f74672e-8f1e-462e-a008-c093aa2d8687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset created\n",
            "Test dataset created\n",
            "<_ParallelMapDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None))>\n",
            "<_ParallelMapDataset element_spec=(TensorSpec(shape=(800, 800, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(800, 800, 1), dtype=tf.uint8, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Dataset"
      ],
      "metadata": {
        "id": "q-hlyuKABiV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = processed_train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = test_dataset.take(3000).batch(BATCH_SIZE)\n",
        "test_batches = processed_test_dataset.skip(3000).take(669).batch(BATCH_SIZE)\n",
        "\n",
        "print(train_batches)\n",
        "\n"
      ],
      "metadata": {
        "id": "YFLyM5Z4A3np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4488eaf8-f213-4390-f5dd-df7a292a634b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 800, 800, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 800, 800, 1), dtype=tf.uint8, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "8zJZHJdc037v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N2RPAAW9q4W"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch = next(iter(test_batches))\n",
        "random_index = np.random.choice(sample_batch[0].shape[0])\n",
        "sample_image, sample_mask = sample_batch[0][random_index], sample_batch[1][random_index]\n",
        "display([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "T27LZx10rQUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Prepare U-Net model"
      ],
      "metadata": {
        "id": "tYObgyvJBn5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def double_conv_block(x, n_filters):\n",
        "\n",
        "    # Conv2D then ReLU activation\n",
        "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "    # Conv2D then ReLU activation\n",
        "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "    f = double_conv_block(x, n_filters)\n",
        "    p = layers.MaxPool2D(2)(f)\n",
        "    p = layers.Dropout(0.2)(p) # 20 percent dropout rate\n",
        "\n",
        "    return f, p\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "    # upsample\n",
        "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "    # concatenate\n",
        "    x = layers.concatenate([x, conv_features])\n",
        "    # dropout\n",
        "    x = layers.Dropout(0.2)(x) # 20 percent dropout rate\n",
        "    # Conv2D twice with ReLU activation\n",
        "    x = double_conv_block(x, n_filters)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_unet_model():\n",
        "\n",
        "    # inputs\n",
        "    inputs = layers.Input(shape=(800,800,3))\n",
        "\n",
        "    p = inputs\n",
        "    i = 0\n",
        "    f = []\n",
        "\n",
        "    # encoder: contracting path - downsample\n",
        "    for n_filter in [64,128,256]:\n",
        "      i += 1\n",
        "      f_val, p = downsample_block(p, n_filter)\n",
        "      f.append(f_val)\n",
        "\n",
        "    # 5 - bottleneck\n",
        "    bottleneck = double_conv_block(p, 512)\n",
        "\n",
        "    # decoder: expanding path - upsample\n",
        "    u = bottleneck\n",
        "    i = 2\n",
        "    for n_filter in [256,128,64]:\n",
        "      u = upsample_block(u, f[i], n_filter)\n",
        "      i -= 1\n",
        "\n",
        "\n",
        "    # outputs\n",
        "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"softmax\")(u)\n",
        "\n",
        "    # unet model with Keras Functional API\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "\n",
        "    return unet_model\n",
        "\n",
        "unet_model = build_unet_model()\n",
        "unet_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSkpSn07A8Dv",
        "outputId": "72a9123e-b704-411c-f049-1041ccf9b33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 800, 800, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 800, 800, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 800, 800, 64)         36928     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 400, 400, 64)         0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 400, 400, 64)         0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 400, 400, 128)        73856     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 400, 400, 128)        147584    ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 200, 200, 128)        0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 200, 200, 128)        0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 200, 200, 256)        295168    ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 200, 200, 256)        590080    ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 100, 100, 256)        0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 100, 100, 256)        0         ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 100, 100, 512)        1180160   ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 100, 100, 512)        2359808   ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 200, 200, 256)        1179904   ['conv2d_7[0][0]']            \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 200, 200, 512)        0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 200, 200, 512)        0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 200, 200, 256)        1179904   ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 200, 200, 256)        590080    ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 400, 400, 128)        295040    ['conv2d_9[0][0]']            \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 400, 400, 256)        0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 400, 400, 256)        0         ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 400, 400, 128)        295040    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 400, 400, 128)        147584    ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 800, 800, 64)         73792     ['conv2d_11[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 800, 800, 128)        0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 800, 800, 128)        0         ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 800, 800, 64)         73792     ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 800, 800, 64)         36928     ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 800, 800, 1)          65        ['conv2d_13[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8557505 (32.64 MB)\n",
            "Trainable params: 8557505 (32.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Save the Model"
      ],
      "metadata": {
        "id": "J7MbX788BzVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "\n",
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                   loss=\"sparse_categorical_crossentropy\",\n",
        "                   metrics=[tf.keras.metrics.Precision()])\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "TRAIN_LENGTH = 3642\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "VAL_SUBSPLITS = 5\n",
        "TEST_LENTH = 1962\n",
        "VALIDATION_STEPS = TEST_LENTH // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "# # # Train the model\n",
        "model_history = unet_model.fit(train_batches,\n",
        "                               epochs=NUM_EPOCHS,\n",
        "                               steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                               validation_steps=VALIDATION_STEPS,\n",
        "                               validation_data=validation_batches, resume='true')\n",
        "# # # Save the model\n",
        "unet_model.save(\"unet_model.h5\")"
      ],
      "metadata": {
        "id": "Cp5y2KdRBAo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and Visualise"
      ],
      "metadata": {
        "id": "lu_OJvtGCBC2"
      }
    }
  ]
}
